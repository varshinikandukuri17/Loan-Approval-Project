# Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
import joblib

# Load dataset
df = pd.read_csv("train.csv")

# Step 1: Drop rows with missing values
df.dropna(inplace=True)

# Step 2: Clean 'Dependents' column (convert '3+' to 3)
df['Dependents'] = df['Dependents'].replace('3+', 3).astype(int)

# Step 3: Encode categorical columns
label_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']
le = LabelEncoder()
for col in label_cols:
    df[col] = le.fit_transform(df[col])

# Step 4: Define features and target
X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = df['Loan_Status']

# Step 5: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Train the model
model = LogisticRegression(max_iter=2000)
model.fit(X_train, y_train)

# Step 7: Evaluate the model
y_pred = model.predict(X_test)
print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("ðŸ“Š Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Step 8: Save the trained model to disk
joblib.dump(model, "loan_model.pkl")
print("âœ… Model saved as loan_model.pkl")

from google.colab import files
files.download('loan_model.pkl')
